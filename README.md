robotic-screenplay
===

* start with a video and its subtitles
* decompose the video into frames (https://github.com/robindemourat/video-to-frames-mosaics)
* analyse each video with densecap and extract the result (https://github.com/robindemourat/node-densecap)
* produce a generative book inspired by it, in which each page is a close-up on the frame, an quote of the current subtitle, and the description given by densecap
